{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# INVESTIGATING LATENT FUNCTONAL NETWORKS IN THE BRAIN DURING EMOTION PERCEPTION\n\n# Project Completed as a part of NeuroMatch Academy 2022 - Computational Neuroscience course\n\n\n# Pod Name: Cachupa\n#  Members: \n# - Rohit Misra \n# - Iosif Lytras\n# - Iraj Ahangari \n# - Gürkan Sinan Yaşar\n# - Dong Chenjie \n\n#  Teaching Assistants: \n# - Bindu Kumari\n# - Tanya Upadhyay\n\n#  Mentors:\n# - Maria Eckstein\n# - Margarita Zachariou\n\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-07-29T13:39:08.177199Z","iopub.execute_input":"2022-07-29T13:39:08.177690Z","iopub.status.idle":"2022-07-29T13:39:08.206925Z","shell.execute_reply.started":"2022-07-29T13:39:08.177599Z","shell.execute_reply":"2022-07-29T13:39:08.206070Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"**SET-UP**","metadata":{}},{"cell_type":"code","source":"from distutils import filelist\nimport numpy as np\nimport nibabel\nfrom nilearn import datasets\n# from nilearn.maskers import NiftiMapsMasker\nfrom nilearn.maskers import NiftiLabelsMasker\nfrom nilearn.connectome import ConnectivityMeasure, group_sparse_covariance\nimport scipy.io\nfrom nilearn import plotting\nimport matplotlib.pyplot as plt\nimport os\nimport networkx as nx\nfrom networkx.algorithms import community\nimport pandas as pd\nfrom sklearn.metrics import silhouette_score\nfrom sklearn.cluster import KMeans\nimport community as community_louvain\nfrom sklearn.decomposition import PCA","metadata":{"execution":{"iopub.status.busy":"2022-07-29T13:39:08.337648Z","iopub.execute_input":"2022-07-29T13:39:08.338301Z","iopub.status.idle":"2022-07-29T13:39:09.945037Z","shell.execute_reply.started":"2022-07-29T13:39:08.338264Z","shell.execute_reply":"2022-07-29T13:39:09.943903Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"**FUNCTION DEFINITONS**","metadata":{}},{"cell_type":"markdown","source":"Functions to return file path given subject and run number","metadata":{}},{"cell_type":"code","source":"# function to return file destination for given subject number and run  number\ndef fmri_filename(subject_number, run_number):\n    filename_prefix = \"/kaggle/input/fmri-dataset-for-emotion-recognition/\"\n    filename_suffix = \"Sub-0\" + str(subject_number) + \"/wrsub-0\" + str(subject_number) + \"_task-emotionalfaces_run-\" + str(run_number) + \"_bold.nii\"\n    return filename_prefix + filename_suffix\n    \ndef get_events_filename(run_number):\n    filename = \"/kaggle/input/events/events/task-emotionalfaces_run-\" + str(run_number) + \"_events.tsv\"\n    return filename","metadata":{"execution":{"iopub.status.busy":"2022-07-29T13:39:09.947310Z","iopub.execute_input":"2022-07-29T13:39:09.947901Z","iopub.status.idle":"2022-07-29T13:39:09.956250Z","shell.execute_reply.started":"2022-07-29T13:39:09.947853Z","shell.execute_reply":"2022-07-29T13:39:09.955100Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"Function to read fMRI file and generate parcellated time series using given atlas","metadata":{}},{"cell_type":"code","source":"def getParcellations(fmri_filename, atlas):\n    # Loading atlas image stored in 'maps'\n    atlas_filename = atlas.maps #atlas['maps']\n    # Loading atlas data stored in 'labels'\n    labels = atlas.labels #atlas['labels']\n    masker = NiftiLabelsMasker(labels_img=atlas_filename, standardize=True,\n                            memory='nilearn_cache', verbose=0)\n    # masker.fit(data)\n    time_series = masker.fit_transform(fmri_filename)\n    return [time_series,labels]","metadata":{"execution":{"iopub.status.busy":"2022-07-29T13:39:09.957526Z","iopub.execute_input":"2022-07-29T13:39:09.957880Z","iopub.status.idle":"2022-07-29T13:39:09.968282Z","shell.execute_reply.started":"2022-07-29T13:39:09.957853Z","shell.execute_reply":"2022-07-29T13:39:09.967509Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"Functions to segment the ROI time series based on stimulus and generate connectivity matrices for each segment","metadata":{}},{"cell_type":"code","source":"def get_correlation_matrices(subject_number, run_number, atlas):\n    bold_filename = fmri_filename(subject_number, run_number)\n    events_filename = get_events_filename(run_number)\n    [ROI_time_series, ROI_labels] = getParcellations(bold_filename, atlas)\n    blocks_time_series, stimulus_labels = segment_time_series(ROI_time_series, events_filename)\n    \n    correlation_matrices = np.ndarray((blocks_time_series[0].shape[1], blocks_time_series[0].shape[1], len(stimulus_labels)))\n    correlation_measure = ConnectivityMeasure(kind='correlation')\n    for i, time_series in enumerate(blocks_time_series):\n        block_corr_matrix = correlation_measure.fit_transform([time_series])[0]\n        correlation_matrices[:,:,i] = block_corr_matrix\n    return [correlation_matrices, stimulus_labels]\n    \ndef segment_time_series(time_series, events_filename):\n    blocks_time_series = []\n    blocks_labels = []\n\n    events_df = pd.read_csv(events_filename,sep=\"\\t\")\n    events_list = events_df.iloc[:,2].tolist()\n    stim_labels_list = ['happy', 'sad', 'angry', 'neutral']\n    for stimulus in stim_labels_list:\n        onset_instances = [i for i,label in enumerate(events_list) if label == stimulus]\n        for onset_index in onset_instances:\n            start = events_df.iloc[onset_index,0]//2\n            stop = start + (events_df.iloc[onset_index,1]//2) - 1\n            blocks_time_series.append(time_series[start:stop,:])\n            blocks_labels.append(stimulus)\n    return [blocks_time_series, blocks_labels]","metadata":{"execution":{"iopub.status.busy":"2022-07-29T13:39:09.971181Z","iopub.execute_input":"2022-07-29T13:39:09.972215Z","iopub.status.idle":"2022-07-29T13:39:09.985598Z","shell.execute_reply.started":"2022-07-29T13:39:09.972165Z","shell.execute_reply":"2022-07-29T13:39:09.984624Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"Functions to Vectorize the connectivity matrices, and convert vectors to connectivity matrices","metadata":{}},{"cell_type":"code","source":"def corr_matrices_to_vectors(correlation_matrices):\n    n = correlation_matrices.shape[0]\n    p = int(n * (n - 1) / 2)\n    vectors = np.ndarray((correlation_matrices.shape[2],p))\n    start = 0\n    for iter in range(n):\n        row = correlation_matrices[iter, iter+1:, :].T\n        end = start + row.shape[1]\n        vectors[:,start:end] = row\n        start = end\n    return vectors\n\n\ndef vector_to_matrix(vector, N):\n    matrix = np.zeros((N,N))\n    start = 0\n    for iter in range(N-1):\n        end = start + N - 1 - iter\n        snippet = vector[start:end]\n        matrix[iter, iter+1:] = snippet\n        matrix[iter+1:, iter] = snippet.T\n        start = end\n    return matrix\n","metadata":{"execution":{"iopub.status.busy":"2022-07-29T13:39:09.987176Z","iopub.execute_input":"2022-07-29T13:39:09.987929Z","iopub.status.idle":"2022-07-29T13:39:10.003219Z","shell.execute_reply.started":"2022-07-29T13:39:09.987885Z","shell.execute_reply":"2022-07-29T13:39:10.001729Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"Functions to cluster data using k-means algorithm for different k values and compare them based on silhouette score","metadata":{}},{"cell_type":"code","source":"# data is a matrix of size \"number of blocks x (n^2 - n)/2\"\n\ndef k_means_score(data, k):\n    km = KMeans(n_clusters=k, random_state=37)\n    km.fit(data)\n    pred = km.predict(data)\n    return [pred, silhouette_score(data, pred)]\n\ndef compare_k_means(data, k_min, k_max):\n    scores = []\n    k_values = np.arange(k_min, k_max+1)\n    for k in range(k_min, k_max + 1):\n        _, score = k_means_score(data, k)\n        scores.append(score)\n    return [k_values, scores]\n\ndef optimal_k_means(data, k):\n    km = KMeans(n_clusters=k, random_state=37)\n    km.fit(data)\n    pred = km.predict(data)\n    centroids = km.cluster_centers_\n    return [pred, centroids]\n\n","metadata":{"execution":{"iopub.status.busy":"2022-07-29T13:39:10.005776Z","iopub.execute_input":"2022-07-29T13:39:10.006272Z","iopub.status.idle":"2022-07-29T13:39:10.022094Z","shell.execute_reply.started":"2022-07-29T13:39:10.006225Z","shell.execute_reply":"2022-07-29T13:39:10.020847Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"Functions to perform graph theoretic analysis of matrices","metadata":{}},{"cell_type":"code","source":"def corr_to_adj(M):\n    threshold = 0.3\n    M[np.abs(M) < threshold] = 0\n    return M\n\ndef graph_analysis(A):\n    G = nx.from_numpy_array(A)\n    # print(G)\n    pos = nx.shell_layout(G)\n    # nx.draw(G, pos = pos)\n    # plt.show()\n    global_efficiency = nx.global_efficiency(G)\n    partitions = community_louvain.best_partition(G)\n    # print(partitions)\n    modularity = community_louvain.modularity(partitions, G)\n    return [global_efficiency, modularity]\n\n","metadata":{"execution":{"iopub.status.busy":"2022-07-29T13:39:10.039524Z","iopub.status.idle":"2022-07-29T13:39:10.040298Z","shell.execute_reply.started":"2022-07-29T13:39:10.040009Z","shell.execute_reply":"2022-07-29T13:39:10.040031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Functions to plot the connectivity matrix and the connectoome given a matrix","metadata":{}},{"cell_type":"code","source":"def get_HO_coords(atlas):\n    atlas_img = atlas['maps']\n    # all ROIs except the background\n    values = np.unique(atlas_img.get_data())[1:] \n    # iterate over Harvard-Oxford ROIs\n    coords = []\n    for v in values:\n        data = np.zeros_like(atlas_img.get_data())\n        data[atlas_img.get_data() == v] = 1\n        xyz = plotting.find_xyz_cut_coords(nibabel.Nifti1Image(data, atlas_img.affine))\n        coords.append(xyz)\n    return coords\n\ndef plotCorrelationMatrix(correlation_matrix,atlas):\n    labels = atlas.labels[1:]\n    np.fill_diagonal(correlation_matrix, 0)\n    plotting.plot_matrix(correlation_matrix,  labels = labels, colorbar=True,\n                     vmax=1, vmin=0.3)\n#     coords = atlas.region_coords\n    \n    # only for harvard oxford atlas \n    coords = get_HO_coords(atlas)\n    plotting.plot_connectome(correlation_matrix, coords,\n                         edge_threshold=\"95%\", colorbar=True)\n\n    plotting.show()\n    view = plotting.view_connectome(correlation_matrix, coords, edge_threshold='90%')\n#     view.open_in_browser()","metadata":{"execution":{"iopub.status.busy":"2022-07-29T13:39:10.041968Z","iopub.status.idle":"2022-07-29T13:39:10.042839Z","shell.execute_reply.started":"2022-07-29T13:39:10.042547Z","shell.execute_reply":"2022-07-29T13:39:10.042575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Function to perform graph analysis on given matrix","metadata":{}},{"cell_type":"code","source":"def rep_network_analysis(matrix):\n#     plotCorrelationMatrix(matrix, atlas)\n    adj_matrix = corr_to_adj(matrix)\n    global_efficiency, modularity = graph_analysis(adj_matrix)\n    print(\"Graph Global Efficieny = \" + str(global_efficiency))\n    print(\"Graph Modularity= \" + str(modularity))\n    return [global_efficiency, modularity]\n    ","metadata":{"execution":{"iopub.status.busy":"2022-07-29T13:39:10.044549Z","iopub.status.idle":"2022-07-29T13:39:10.045349Z","shell.execute_reply.started":"2022-07-29T13:39:10.045062Z","shell.execute_reply":"2022-07-29T13:39:10.045090Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**MAIN**","metadata":{}},{"cell_type":"markdown","source":"1. Iterate over all fMRI files and generate correlation matrices for all blocks in each run. ","metadata":{}},{"cell_type":"code","source":"# total_subjects = 5\n# total_runs_per_subject = 5\n\n# # atlas = datasets.fetch_atlas_aal(version='SPM12', data_dir=None, url=None, resume=True, verbose=1)\n# atlas = datasets.fetch_atlas_harvard_oxford('cort-maxprob-thr25-2mm')\n# n = len(atlas.labels)\n# all_correlation_matrices = np.ndarray((n-1,n-1))\n# all_stimulus_labels = []\n# for subject_num in range(1,total_subjects + 1):\n#     for run_num in range(1,total_runs_per_subject + 1):\n#         [runwise_corr_matrices, stimulus_labels] = get_correlation_matrices(subject_num, run_num, atlas)\n#         all_correlation_matrices = np.dstack((all_correlation_matrices, runwise_corr_matrices))\n#         all_stimulus_labels.extend(stimulus_labels)\n        \n# all_correlation_matrices = all_correlation_matrices[:,:,1:]\n# print(all_correlation_matrices.shape)\n","metadata":{"execution":{"iopub.status.busy":"2022-07-29T13:39:10.047684Z","iopub.status.idle":"2022-07-29T13:39:10.048439Z","shell.execute_reply.started":"2022-07-29T13:39:10.048163Z","shell.execute_reply":"2022-07-29T13:39:10.048189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"2. Vectorize the connectivity matrices","metadata":{}},{"cell_type":"code","source":"# vectorized_data = corr_matrices_to_vectors(all_correlation_matrices)\n# print(vectorized_data.shape)","metadata":{"execution":{"iopub.status.busy":"2022-07-29T13:39:10.049997Z","iopub.status.idle":"2022-07-29T13:39:10.050795Z","shell.execute_reply.started":"2022-07-29T13:39:10.050517Z","shell.execute_reply":"2022-07-29T13:39:10.050553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"3. Perform PCA to reduce dimensionality of the vectors","metadata":{}},{"cell_type":"code","source":"# pca =  PCA(n_components= 100)\n# pca.fit(vectorized_data)\n# data = pca.transform(vectorized_data)","metadata":{"execution":{"iopub.status.busy":"2022-07-29T13:39:10.052396Z","iopub.status.idle":"2022-07-29T13:39:10.052987Z","shell.execute_reply.started":"2022-07-29T13:39:10.052726Z","shell.execute_reply":"2022-07-29T13:39:10.052751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"4. Cluster the data using k-means clustering for a range of k-values","metadata":{}},{"cell_type":"code","source":"# k_values, scores = compare_k_means(data, 2, 15)\n\n# plt.plot(k_values, scores)\n# plt.xlabel('k value')\n# plt.ylabel('Silhouette score')\n# plt.show()\n\n# # pick max","metadata":{"execution":{"iopub.status.busy":"2022-07-29T13:39:10.055047Z","iopub.status.idle":"2022-07-29T13:39:10.056057Z","shell.execute_reply.started":"2022-07-29T13:39:10.055525Z","shell.execute_reply":"2022-07-29T13:39:10.055591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"5. Find the k that maximises silhouette score","metadata":{}},{"cell_type":"code","source":"# k_opt = k_values[np.argmax(scores)]\n# print(k_opt)","metadata":{"execution":{"iopub.status.busy":"2022-07-29T13:39:10.059319Z","iopub.status.idle":"2022-07-29T13:39:10.059874Z","shell.execute_reply.started":"2022-07-29T13:39:10.059560Z","shell.execute_reply":"2022-07-29T13:39:10.059591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"6. Convert cluster centroids to connectivity matrices to get representative networks ","metadata":{}},{"cell_type":"code","source":"# cluster_labels, centroids_pca = optimal_k_means(data, k_opt)\n# centroids = pca.inverse_transform(centroids_pca)\n# N = len(atlas.labels[1:])\n# rep_networks = np.ndarray((N,N,centroids.shape[0]))\n# for index in range(centroids.shape[0]):\n#     rep_networks[:,:,index] = vector_to_matrix(centroids[index,:], N)\n    \n# print(rep_networks.shape)","metadata":{"execution":{"iopub.status.busy":"2022-07-29T13:39:10.063534Z","iopub.status.idle":"2022-07-29T13:39:10.064130Z","shell.execute_reply.started":"2022-07-29T13:39:10.063846Z","shell.execute_reply":"2022-07-29T13:39:10.063875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"7. Generate graph theoretic metrics for all represenatative networks","metadata":{}},{"cell_type":"code","source":"# global_efficiency_list = []\n# modularity_list = []\n# for index in range(rep_networks.shape[2]):\n#     eff, mod = rep_network_analysis(rep_networks[:,:,index])\n#     global_efficiency_list.append(eff)\n#     modularity_list.append(mod)\n    \n","metadata":{"execution":{"iopub.status.busy":"2022-07-29T13:39:10.162617Z","iopub.execute_input":"2022-07-29T13:39:10.163691Z","iopub.status.idle":"2022-07-29T13:39:10.170361Z","shell.execute_reply.started":"2022-07-29T13:39:10.163640Z","shell.execute_reply":"2022-07-29T13:39:10.168746Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"8. (A) Compare graph metrics using bar graphs","metadata":{}},{"cell_type":"code","source":"# network_index = np.arange(k_opt) + 1\n\n# plt.bar(network_index, global_efficiency_list) \n# plt.xlabel(\"Representative Networks\")\n# plt.ylabel(\"Global Efficiency\")\n# plt.title(\"Global Efficiency of Representative Networks\")\n# plt.savefig(\"eff_bar\")\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-29T13:39:10.287410Z","iopub.execute_input":"2022-07-29T13:39:10.288598Z","iopub.status.idle":"2022-07-29T13:39:10.292643Z","shell.execute_reply.started":"2022-07-29T13:39:10.288555Z","shell.execute_reply":"2022-07-29T13:39:10.291724Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"8. (B) Compare graph metrics using bar graphs","metadata":{}},{"cell_type":"code","source":"# plt.bar(network_index, modularity_list) \n# plt.xlabel(\"Representative Networks\")\n# plt.ylabel(\"Modularity\")\n# plt.title(\"Modularity of Representative Networks\")\n# plt.savefig(\"modularity_bar\")\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-29T13:39:10.405368Z","iopub.execute_input":"2022-07-29T13:39:10.406165Z","iopub.status.idle":"2022-07-29T13:39:10.411073Z","shell.execute_reply.started":"2022-07-29T13:39:10.406124Z","shell.execute_reply":"2022-07-29T13:39:10.409833Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"9. (A) Display Representative networks","metadata":{}},{"cell_type":"code","source":"# plotCorrelationMatrix(rep_networks[:,:,0], atlas)","metadata":{"execution":{"iopub.status.busy":"2022-07-29T13:39:10.506103Z","iopub.execute_input":"2022-07-29T13:39:10.507126Z","iopub.status.idle":"2022-07-29T13:39:10.511031Z","shell.execute_reply.started":"2022-07-29T13:39:10.507083Z","shell.execute_reply":"2022-07-29T13:39:10.509937Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"9. (B) Display Representative networks","metadata":{}},{"cell_type":"code","source":"# plotCorrelationMatrix(rep_networks[:,:,1], atlas)\n","metadata":{"execution":{"iopub.status.busy":"2022-07-29T13:39:10.591822Z","iopub.execute_input":"2022-07-29T13:39:10.592776Z","iopub.status.idle":"2022-07-29T13:39:10.596915Z","shell.execute_reply.started":"2022-07-29T13:39:10.592741Z","shell.execute_reply":"2022-07-29T13:39:10.595907Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"10. Visualise unclustered data using t-SNE","metadata":{}},{"cell_type":"code","source":"# # visualization with tSNE in two dinemsions\n# from sklearn.manifold import TSNE\n\n# tsne = TSNE(n_components=2, verbose=1, random_state=123)\n# embed_2D = tsne.fit_transform(vectorized_data)\n\n# component_1 = embed_2D[:,0]\n# component_2 = embed_2D[:,1]\n\n\n# plt.scatter(component_1, component_2)\n# plt.xlabel('component 1')\n# plt.ylabel('component 2')\n","metadata":{"execution":{"iopub.status.busy":"2022-07-29T13:39:10.716984Z","iopub.execute_input":"2022-07-29T13:39:10.717667Z","iopub.status.idle":"2022-07-29T13:39:10.721437Z","shell.execute_reply.started":"2022-07-29T13:39:10.717634Z","shell.execute_reply":"2022-07-29T13:39:10.720679Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"11. Get composition of clusters based on experimenter labels","metadata":{}},{"cell_type":"code","source":"# stim_labels_list = ['happy', 'sad', 'angry', 'neutral']\n# composition = np.zeros((len(np.unique(cluster_labels)), len(stim_labels_list)))\n# for i in range(len(cluster_labels)):\n#     composition[cluster_labels[i], stim_labels_list.index(all_stimulus_labels[i])] += 1\n    \n# print(composition)","metadata":{"execution":{"iopub.status.busy":"2022-07-29T13:39:10.831037Z","iopub.execute_input":"2022-07-29T13:39:10.831998Z","iopub.status.idle":"2022-07-29T13:39:10.836173Z","shell.execute_reply.started":"2022-07-29T13:39:10.831961Z","shell.execute_reply":"2022-07-29T13:39:10.835163Z"},"trusted":true},"execution_count":15,"outputs":[]}]}